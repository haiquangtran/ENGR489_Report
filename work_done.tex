\chapter{Work Done}\label{C:work_done}

\section{Limitations}

The main limitations of this project is that it focuses on a mobile application, rather than a website application. This forces some limitations in terms of how users will interact with the system since with a mobile interface, the small form factor affects many changes which will be described later on. Since existing components of WOTM are done in the programming language Ruby, it means we are confined to this language. In addition, the data in the application has already been modelled, including the dishes, restaurants, users and so on. The only data that had not been modelled was the data required for the recommender system such as like/dislikes and preferences.   

\section{Design Decisions}

\subsection{Open source projects}
This section identifies the open source projects that were considered for this project.

Open source projects can be utilised to fit the projects specific needs, as opposed to the alternative of starting from scratch. This saves time, allowing the focus to be on the CF techniques themselves. The open source community has a range of available projects. In particular, a range of machine learning libraries are available that incorporate various types of CF techniques. Spotify have an open-source project called Annoy \cite{annoy} that uses a CF neighbourhood approach. Recommendable \cite{recommendable} also uses a CF neighbourhood approach and is written in Ruby, making it easy to setup with the existing WOTM components \cite{recommendable}. There were many other open-source projects such as EasyRec \cite{easyrec}, Apache Mahout \cite{mahoutaction}, Lenskit \cite{lenskit}, and so forth, containing a range of CF techniques. 

Eventually, this led to the discovery of PredictionIO, the main open-source project used in this project. The following section explains the reasons why PredictionIO was chosen. 
% \subsubsection{Apache Mahout}

% Apache Mahout is an open source library written in Java \cite{mahout, mahoutaction}. Apache Mahout is made to run with Apache Hadoop to do parallel processing for scalability. Apache Mahout's main goal is to "build an environment for quickly creating scalable performant machine learning applications" \cite{mahout}. It contains many machine learning algorithms and forms of CF. In particular, it contains user-based CF, item-based CF, matrix factorization models using alternating least squares, and a weighted matrix factorization approach using singular value decomposition. It also contains built in similarity measures such as Pearson's correlation, Euclidean distance, Cosine similarity, Spearman's Correlation and more. These similarity measures can easily be switched out with different CF algorithms and so on. 
% Although Apache Mahout looks appealing, we did not choose to use it because it would require extensive overhead. Since it is a Java library it requires a Java Virtual Machine (JVM) to be executed. Since our database is in PostgreSQL we would need tools such as Java Database Connectivity (JDBC) to communicate with the database to feed the data to the algorithms. Another option would be using JRuby which is a implementation of Ruby that runs on a Java Virtual Machine allowing the use of Ruby and Java code for easy integration with Java libraries.
% There is JRuby Mahout Library that could be used but is not maintained or updated frequently. Although a REST interface could be used with Java, it would require us to incorporate additional frameworks, in addition to using a server such as Tomcat to run on. Because of these reasons, we decided not to use this library for now.

% \subsubsection{Recommendable}

% Recommendable is an open source project written in Ruby that uses a user-based CF approach. It allows you to add a recommendation engine for Likes and Dislikes into a Ruby application. Since our components are written in Ruby, it means that we can easily incorporate this gem into our recommendations component to provide recommendations. It uses a modified version of Jaccard's Index as the similarity measure to find similar users. Recommendable uses a key-value store called Redis which is used typically used as a cache system for other systems but in this case, it is used to deliver recommendations. The reason why Redis is suitable for CF is because CF logic "is based almost entirely on set math, and Redis is blazing fast for this" \cite{recommendable}. Recommendable only supports Binary events such as Like/Dislike, however it contains other events such as bookmarks which allows users to store their favourite items. 

% We decided to implement and use this open source software first because it provides basic functionality for CF that we can easily modify. In particular, we found it to the be easiest to integrate with our existing components to get recommendations working quickly because it is written in Ruby, and there is clear documentation. Because of this, we decided that we should get a basic form of CF working first, rather than start off with anything complex. From this we will extend this system to suit our needs, being able to easily swap out the similarity measures for different ones. 

\subsubsection{PredictionIO}

PredictionIO is an open-source machine learning server used to "build and deploy predictive applications in a fraction of the time" \cite{predictionio, predictionio2}.

% These engines are fed in application specific data, and contain algorithms that are used to produce recommendations. Engines are deployed as web services, allowing applications to query information from the web service. This means we can easily swap and evaluate various CF algorithms on different engines. 

% We can deploy these engines as a web service, and WOTM can query the engine to receive recommendations. Different algorithms can also be built on various engines which results can then be aggregated together to provide a way to implement hybrid CF techniques. 

\begin{figure}
\centering
\includegraphics[scale=0.35]{images/predictionIO}
\caption{ How existing applications interact with PredictionIO \cite{predictionio}}
\label{fig:predictionIO}
\end{figure}


Figure \ref{fig:predictionIO} represents how PredictionIO is made to integrate with existing applications \cite{predictionio}. Data such as rating events from WOTM is sent to the Event Server where it is stored on PredictionIO. PredictionIO uses a distributed database that is easily scalable. Data from the event server is then used by algorithms from the engines to learn recommendations. These engines are deployed as distributed web services. WOTM can query these deployed engines to retrieve the top N recommendations for a specific user. 

The main advantage of using PredictionIO is that engines can be easily swapped out making it easy to examine and evaluate various CF techniques. This saves time, switching the main focus on CF algorithms rather than configuring settings to accommodate various technology and tools.

Additionally, these engines implement a DASE architecture. DASE stands for Data, Algorithms, Serving, and Evaluator. These components are considered to be independent in the engine which allows for separation of concerns. Implementation of various algorithms can be applied at the Algorithms stage, and enables results from the various algorithms to be combined at the Serving stage to produce hybrid CF approaches for recommendations.

PredictionIO already contains a range of customizable engines, including engines that use SVD techniques for CF. The PredictionIO community is active and new engines are frequently being produced. There is concise documentation in addition to support available. For these reasons, we found PredictionIO to be our best candidate and decided to use it. 

% \subsection{Online Learning vs Offline Learning}

% In a mobile application, speed and performance of recommendations is arguably more important than the prediction-accuracy. For instance, a user is more likely to use an application that provides fast recommendations to the users but less accurate recommendations, as opposed to an application that provides slow recommendations to the users but are accurate. In this case, the former is to be more accepted because users are able to easily skip inaccurate recommendations, whereas in the latter, users will have to wait for the recommendations to appear which may cause their attention to drift. 

% With this in consideration, it is important to provide fast recommendations to users, thus a model-based approaches would be more appropriate than neighbourhood methods. A model-based CF approach means that a model can be constructed and trained offline. Once the model is deployed, it will provide instant recommendations to the users because less computation needs to be done in real time, since the model has learnt what the user likes offline. As well as this, a model based approach means that expensive computation can be computed offline, providing high scalability. However, the disadvantage of a CF model based approach is that it must be regularly trained to take into account the recent new actions of the users. Therefore, regular intervals to train the model need to be defined depending on how often users rate dishes.

% Neighbourhood methods of CF perform online learning, meaning that they do the computation in real time. For instance, in user-based CF when a user likes a dish, then the algorithm will be performed then and there, finding similar users, then finding neighbours that are similar to that user, providing a recommendation. This technique is easy to implement, but does not scale well, and is slower than the modelled approach. However, depending on the size of data that is expected to be collected from this 'WOTM', it may be a valid approach if the data is not expected to be large (millions of ratings). As new users and new items grow in the application, it is expected that the amount of ratings will exponentially grow as well, therefore there is a possibility that scalability may have to be considered in the long term. As of now, we will focus on the performance of the recommender system.  

% For this reason, we will examine both online learning and offline learning, and see how implementations of the CF algorithm affect the performance of the recommendations that are produced.  


\subsection{User Experience}

With a mobile application it encourages user interaction that differs from that of a website. For instance, users are encouraged to use touch events to navigate through pages or to perform certain actions. This leads design decisions that accommodate such interactions, making it easier for users to perform tasks on mobile applications. The user experience of WOTM affects how rating data is collected from users, which can affect the recommendation system. The following section explains the design decisions for collecting events from users, and how these events can affect the recommender system. 

\subsection{Explicit Feedback}

Recommender systems rely on different types of input data \cite{koren2009matrix}. Explicit data is referred to as a direct record of someones interest of an item. For example, Netflix collects star ratings for movies, and TiVo users collect data from having a thumbs up or thumbs down directly indicating that they like or dislike a particular item \cite{koren2009matrix}. These events are mapped directly in the ratings matrix, and explain directly how a user feels about an item. 
The next section explains the design decisions regarding the explicit feedback we will collect in the WOTM application.

\subsubsection{Boolean Ratings vs Ternary Ratings vs Likert Scale Ratings}

Although prediction-accuracy is important, it is not the only factor that a recommender should focus on and acts as one facet in wide range of facets \cite{martin2009recsys}. \citeauthor{martin2009recsys} explains that the goal of a recommender system is to improve user experience however, designing a recommender system to fit a specific application remains a challenge, and recommender system ratings should be based on the user experience \cite{martin2009recsys}. By focusing on user experience, users will be able to easily rate food dishes, in turn, leading to the system collecting more information for the recommender system from ease of use. For this reason, a simple model allowing users to easily rate a dish such as a binary rating (Like/Neutral) or a ternary rating (like/neutral/dislike) is preferred over Likert scale ratings. This provides simplicity, but means recommendations will not be as accurate as Likert scale ratings such as 1-5 stars or 1-10 stars. By easing the user experience for rating food dishes it can increase data collection at the expense of accuracy. In fact, \citeauthor{movieratings} found that users provided more ratings that had options to "like" or "dislike" than users with only one rating option \cite{schafer2007collaborative, movieratings}. 

Using Likert scaled ratings mean that we learn more about the user preferences because of the scaled factor indicating how much the user likes a dish or not. This means that model based CF techniques are able to learn what the user likes and dislikes faster leading to more accurate recommendations. However, it is difficult to see how good a dish is by using a Likert scale system such as a 1-5 star rating since the ratings will be skewed. For example, if a dish had a 5 star rating, it usually means that only 1 or 2 people have rated that dish. Ratings such as 3.5 stars may mean that it is a good dish, but from the way it is displayed, may seem otherwise. \citeauthor{interface} explains that by displaying what other users think of an item, the active user tends be influenced by the opinions of others, leading to bias ratings \cite{interface}. An example would be a user rating a dish higher than they would normally because the food dish has an average of 4.5 stars. This can lead to inaccurate recommendations for the active user in the long term, because users may be influenced by others opinion \cite{interface}. \citeauthor{interface} argues that the way ratings are collected, and displayed influence how others will rate the dish. Considerations like this have to be taken into account to understand how the user will perceive and interact with the recommender system.  

A trade-off to consider is whether or not accurate recommendations are more important than the user experience. Since WOTM aims at being a mobile application, the limitations are the small form factor that mobile phone screens have. With a Likert scale rating system, the user has to be shown these possible options in order to rate a dish. This can take up additional space that is not needed on small screens. Because of this, having a 1-5 star rating system may degrade the user experience as opposed to a simple like/dislike rating system. 

% This may lead to less data being collected and in the long term affect the recommendations that are provided to the users. But on the other hand, since it uses scaled ratings, it means we are able to learn more information from each rating. This means that the recommender system is more likely to predict accurate recommendations with less ratings. 

For a mobile application, prediction-accuracy of the recommender system may not matter a great deal. For instance, a recommender system could predict two dishes the user may like based on previous rating patterns. The first dish is predicted with a 90\% prediction accuracy, and the second dish is predicted with a 70\% prediction accuracy that the user will like these dishes. But is the difference in prediction accuracy important if the user likes both dishes? As long as the recommender system has provided the user with dishes they like, the accuracy between those predicted dishes do not drastically matter. In addition, dishes with higher predicted accuracy may seem like obvious choices that the user may have already tried, whereas dishes with a lower predicted accuracy may lead to less obvious dishes that they may like, but have not tried yet. A recommender system using boolean or ternary values would eventually reach prediction accuracy similar to using likert scale ratings. Although this will happen in the long term, new ratings will most likely lead to less accurate predictions that join the system in the short term until more ratings are collected. 

Foursquare is an application that asks users to rate items according to a series of questions. These questions consist of "What do you like about this place?", "What is this place known for?" and so on. From these questions they are able infer a particular rating for the item, as well as collect data from users to give more accurate recommendations. This rating system may risk users not rating the items because of the long list of questions it asks. \cite{martin2009recsys} explains that part of the challenge is to design interfaces "that give users control over the recommendation process without overwhelming the user or rendering the tool too complicated for novice users." 

For these reasons, we found that simple like/dislike events would best suit the collection of data for the recommender system because of the simplified structure which increases the user experience. The recommender system can be extended to take in additional events that may portray additional information such as a "want" indicating that a user "wants" a dish but has not yet tried it before. However, caution must be taken as more events will affect the user experience of the application, but may lead to more accurate recommendations. 

\subsection{Implicit Feedback}

When explicit feedback is not available, implicit data can be used to infer preferences from users \cite{koren2009matrix}. Implicit feedback is referred to as an indirect reflection of someones interest in an item. Implicit feedback can be from observing user behaviour. This could include click through data, browsing history, the way users react to certain events, search patterns, and so on \cite{koren2009matrix}. Implicit feedback can be collected to increase the accuracy of recommendations to users by being combined with explicit feedback, or can fill in the ratings matrix when explicit events are not available, alleviating the 'cold start' problem as it makes the matrix more dense. The next section explains design decisions regarding the implicit feedback in WOTM.

\subsubsection{Additional Events}

Netflix and other sites such as Amazon.com \cite{koren2009matrix, schafer2007collaborative} use implicit feedback such as views and purchase history in their recommender systems. These events indicate some form of interest in the user, however are less practical to apply for a mobile application. For example, on a website, many products are able to be shown to the user. When a user selects a product it will indicate some form of implicit feedback such as the user is interested in that product. With the WOTM mobile application, it can be diffiuclt showing a range of food dishes to users because of the small screen size. This can make it difficult to collect additional implicit feedback. As well as this, purchase history and similar events are not practical because users are unlikely to indicate that they have purchased a dish after they have tried it. Explicit events such as like and dislike already infer that they have tried the dish, which make purchase history redundant. The implicit event of commenting on a dish may provide valuable information, perhaps commenting on a dish means that there is a strong interest or disinterest a user has about a specific dish. However, this is impractical because we do not know if the comment is good or bad without using extraction techniques.

A consideration to think about is how to collect feedback on how the user feels about the recommendations produced by the recommender system. This can be used to gather more events, to make predictions more accurate. For instance, a user can indicate that they liked/disliked the recommendation that was shown to them, or they could skip it altogether meaning that they they do not have an opinion about it. Although the flaw in this method is that recommendations may be dishes the user has not tried yet. Therefore, they may keep skipping through recommendations and provide no valid feedback to them. Although this may happen, an assumption is that user "Like" events may be used for a dish that the user has not yet tried, but is interested in. 

For these reasons, we do not use any implicit events in our recommendation system but this may change in future. 

\section{Implementation}

This section explains what has been implemented according to the design decisions in the previous section. 

% \subsection{Neighbourhood CF}

% Using Recommendable, we have an implementation of the basic nearest neighbour CF technique. It is able to provide recommendations based on like/dislike events of the users. In addition, we are able to implement bookmark events so users can save their favourite dishes. Recommendable also provides a method to see the most popular dishes, which can be shown to users if they have not rated any dishes yet. This approach uses online learning, and does real time computation. The recommender system uses user based CF with a modified Jaccard's similarity measure described below.

% \subsubsection{Modified Jaccard Index}

% Jaccardian similarity coefficient is an intuitive way of comparing people when the rating system is binary \cite{recommendable}. Recommendable uses a modified version. The modified version of Jaccard's Index is as shown:
% \textcolor{red}{TODO: EXPLAIN HERE}
% \[ u^n - u^n = z^n \]

\subsection{Latent Factor Models}

PredictionIO \cite{predictionio} provides many template engines, some of which use CF algorithms to make recommendations to users. In particular, there is a template engine that uses Singular Value Decomposition, learning user preferences based on previous rating patterns. This engine is called the "E-Commerce Recommendation Engine", and will be built upon to suit our use case. The following section explains the E-Commerce Recommendation Engine and the changes that have been made to it for this project. 

\subsubsection{E-Commerce Recommendation Engine}

The E-Commerce Recommendation Engine is written in the programming language Scala and is made to provide personalised recommendations for e-commerce applications. This engine uses Singular Value Decomposition which is a model-based CF technique. This means that the model trains on the users rating patterns to learn about recommendations that the users may be interested in. Training occurs offline. Default events in the engine are view events and purchase events. The engine also comes with the following out of the box functionality \cite{predictionio}.
\begin{enumerate}
 \item Exclude out-of-stock items
 \item Provide recommendation to new users who sign up after the model is trained
 \item Recommend unseen items only (configurable)
 \item Recommend popular items if no information about the user is available
\end{enumerate}

% TODO: REDO THIS
Since "view" and "purchase" ratings are implicit events and not explicit events such as Likert scaled ratings from values 1-5, the implicit events have to be represented differently in the ratings matrix. Implicit events are represented in the ratings matrix by the combination of binary preferences and the confidence values of these binary preferences being true instead. An implicit event such as "view" or "purchase" event maps to a binary preference value of 1. Missing events map to a binary preference value of 0. 

A binary preference value of 1 indicates that the user likes the item, and a binary preference of 0 indicates no preference for the user. Additionally, implicit events also have a confidence value associated with it. These confidence values represent the confidence levels of the binary preference values being true. In this case, preference values for the "view" and "purchase" events correlate to the value of 1. Multiple identical events such as a user viewing the same item multiple times correlate to higher confidence levels since the confidence level is an aggregation of preference values. This means that there is a higher confidence level that the binary preference value is true, in this case, that the user will like the item because the user viewed or purchased the same item multiple times, recommendations taking this into account. 

Singular Value Decomposition is then used with the same steps in equation \ref{eq:2}, except with a different minimization equation that considers the implicit events. This minimization equation is for implicit events which is the following \cite{implicit}.

\begin{equation}\label{eq:3}\tag{3}
\displaystyle min_{q*,p*} \sum_{ (u,i) \in K} c_{ui}(b_{ui} - q_{i}^T p_{u})^2 + \lambda (\| q_{i} \|^2 + \| p_{u} \|^2 )
\end{equation}

In this equation, \begin{math} c_{ui} \end{math} is the confidence level and \begin{math} b_{ui} \end{math} is the binary preference value. 

\subsubsection{Modifications to the Engine}

Using this template, we modified this engine to take into account "Like" and "Dislike" events, removing the view and purchase events. We modified the CF algorithm in the engine to consider a "Like" event as positive result, giving it the preference value of a 1. In contrast, we made the algorithm in the engine consider a "Dislike" event to be a negative result, giving it the preference value of a -1. Since users may be able change their minds about liking or disliking a dish, we modified the CF algorithm to only take into account the most recent like/dislike event that occurs from the user, if there are multiple identical like/dislike events on a dish from that user. Filtering in this recommendation system was also added. Users are now able to filter recommendations based on their preferences such as their meat type, their cuisine type, and their food type. As well as this, users can see recommendations that are within their price range, if specified. 

If dishes are no longer available, then we are able to send a query to the recommendation engine to tell it that the dish is unavailable. Another feature is that we are also able to send a query to the recommendation engine to say that a user has already seen that dish, and not to recommend that seen dish anymore. In this way, the user only sees new dishes that they have not been recommended yet.

This model recommends dishes to users as soon as they have liked a dish. These recommendations are also based on the ratings of other users rating patterns, which means that the ratings matrix should be dense. If the model cannot learn what the user likes, or the user has not rated anything yet, then it defaults to recommending the most popular dishes to the users. The advantage of this is that users get to see the trending dishes that other users prefer, however the disadvantage is that it may create bias results in the system because popular dishes will only be seen by new users. This means that new users will only rate the popular dishes, causing problems in the recommender engine. To extend this engine, we need to only recommend dishes to users after they have rated x amount of dishes. Random dishes should be shown until they ahve rated x amount of dishes. 