\chapter{Evaluation}\label{C:evaluation}

\section{Experimental Objectives}

\subsection{Experimental Validity}

\subsection{Measurement Platform}

\section{Experimental Design}


\section{Methods?}

\subsection{User Dataset}

% \cite{martin2009recsys}
% Examples of this problem
% include the lack of standard treatment of items for which
% the recommender is unable to make a prediction. The broader
% goal of user-centered holistic evaluation, including A/B testing
% of the short- and long-term effects of recommendation differences,
% is still met by only a few research groups and companies
% that have the live systems and resources for such evaluation.

% Deploying innovative recommenders is still too hard, and there is a substantial need for research platforms where innovations can be tested without first building up a community of thousands of users. 
\todo{Show proportions of data}

\section{Experimental Setup}

\section{Issues}

\section{Offline Evaluation}

\subsection{Data Partitioning}

\subsection{Parameter Tuning}

\subsection{Offline Metrics}

\subsubsection{Binary List}

\subsubsection{Precision \& Recall}

\subsubsection{Classification Accuracy}

\subsubsection{ROC Curves}

\subsubsection{Thresholding}

\section{Online Evaluation}

\section{Results}

\section{Limitations}

\section{Discussion}


